{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jugando con Probabilidades y Python\n",
    "\n",
    "\n",
    "### La coincidencia de cumpleaños\n",
    "\n",
    "Aquí vemos la solución de la paradija del cumpleaños que vimos en el apartado de proabilidad.\n",
    "\n",
    "La [paradoja del cumpleaños](https://es.wikipedia.org/wiki/Paradoja_del_cumplea%C3%B1os) es un problema muy conocido en el campo de la probabilidad. Plantea las siguientes interesantes preguntas: ¿Cuál es la probabilidad de que, en un grupo de personas elegidas al azar, al menos dos de ellas habrán nacido el mismo día del año? ¿Cuántas personas son necesarias para asegurar una probabilidad mayor al 50%?. \n",
    "\n",
    "Calcular esa probabilidad es complicado, así que vamos a calcular la probabilidad de que no coincidad, suponinedo que con eventos independietes (es decir las podemos multiplicar), y luego calcularemos la probabilidad de que coincidan como 1 menos esa probabilidad. \n",
    "\n",
    "Excluyendo el 29 de febrero de nuestros cálculos y asumiendo que los restantes 365 días de posibles cumpleaños son igualmente probables, vamos a calcular esas dós cuestiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Ejemplo situación 2 La coincidencia de cumpleaños\n",
    "\n",
    "prob = 1.0\n",
    "asistentes = 50\n",
    "\n",
    "# calculamos la probabilidad de coincidencia para 50 asistentes\n",
    "\n",
    "for i in range(asistentes):\n",
    "    prob = prob * (365-i)/365\n",
    "\n",
    "print(\"Probabilidad de que compartan una misma fecha de cumpleaños es {0:.2f}\"\n",
    "      .format(1 - prob))\n",
    "\n",
    "# Calculamos el número de asistentes necesarios para asegurar \n",
    "# que la probabilidad de coincidencia sea mayor del 50%\n",
    "\n",
    "asistentes=0\n",
    "prob= 1 \n",
    "while prob > 0.5:\n",
    "    prob = prob * (365-i)/365\n",
    "    asistentes +=1\n",
    "\n",
    "print(\"Para asegurar que la probabilidad es mayor del 50% necesitamos {0} asistentes\".format(asistentes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T82T2FuSk8YV"
   },
   "source": [
    "## Variables aleatorias. Vamos a tirar un dado\n",
    "\n",
    "Vamos a trabajar con variables discretas, y en este caso vamos a vamos a reproducir un dado con la librería `random` que forma parte de la librería estandar de Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1102
    },
    "colab_type": "code",
    "id": "e9u4frvmgmfm",
    "outputId": "1e16fa1e-4a1b-4692-f780-0087ad3b3652"
   },
   "outputs": [],
   "source": [
    "# importa la libreria random. puedes utilizar dir() para entender lo que ofrece\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "sSnWP25Sq8Ri",
    "outputId": "009e0b1f-f781-45bc-9a48-be85d213931d"
   },
   "outputs": [],
   "source": [
    "# utiliza help para obtener ayuda sobre el metodo randint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "uF5EmVCfrFEG",
    "outputId": "387cbb1d-30db-4e4e-c7d4-4b21e936e61d"
   },
   "outputs": [],
   "source": [
    "# utiliza randint() para simular un dado y haz una tirada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "BkMh_c9hrMSE",
    "outputId": "2a5b7290-2dcf-4940-e46a-c0563bbb7d66"
   },
   "outputs": [],
   "source": [
    "# ahora haz 20 tiradas, y crea una lista con las tiradas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "9w9ToSNIrT3y",
    "outputId": "a4a39b3e-7c61-406b-84fe-10a78effc475"
   },
   "outputs": [],
   "source": [
    "# Vamos a calcular la media de las tiradas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "57l2u-wGrtv7",
    "outputId": "3e12e19a-ba9a-435e-98d5-fba4c74acfbd"
   },
   "outputs": [],
   "source": [
    "# Calcula ahora la mediana\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula la moda de las tiradas \n",
    "\n",
    "\n",
    "\n",
    "# se te ocurre otra forma de calcularla?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viendo como evoluciona el número de 6 cuando sacamos más jugadas\n",
    "\n",
    "Vamos a ver ahora como evoluciona el número de seises que obtenemos al lanzar el dado 10000 veces. Vamos a crear una lista en la que cada elemento sea el número de ocurrencias del número 6 dividido entre el número de lanzamientos. \n",
    "\n",
    "crea una lista llamadada ``frecuencia_seis[]`` que almacene estos valores \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# tu código aquí\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos a tratar de hacerlo gráficamente\n",
    "¿Hacia que valor debería converger los números que forman la lista frecuencia_seis? \n",
    "Revisa la ley de los grandes números para la moneda, y aplica un poco de lógica para este caso.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resolviendo el problema de Monty Hall\n",
    "\n",
    "Este problema, más conocido con el nombre de [Monty Hall](https://es.wikipedia.org/wiki/Problema_de_Monty_Hall).\n",
    "En primer lugar trata de simular el problema de Monty Hall con Python, para ver cuantas veces gana el concursante y cuantas pierde. Realiza por ejemplo 10000 simulaciones del problema, en las que el usuario cambia siempre de puerta. Después puedes comparar con 10000 simulaciones en las que el usuario no cambie de puertas.\n",
    "Cuales son los resultados?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monty Hall sin Bayes - Simulación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# vamos a tratar de solucionar el problema de Monty Hall simulando como jugaría el jugador\n",
    "# Simula 10000 jugadas\n",
    "# Puedes escoger a priori la estrategia: haz 10000 simulaciones en las que el jugador siempre cambie la puerta\n",
    "# y también puedes ejecutar 10000 en las que no cambie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monthy Hall - una aproximación bayesiana\n",
    "\n",
    "Trata de resolver ahora el problema de Monthy Hall utilizando el teorema de Bayes.\n",
    "Puedes escribir la solución, o programar el código. Lo que prefieras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# El problema de las Cookies\n",
    "\n",
    "Imagina que tienes 2 botes con galletas. El primero contiene 30 cokkies de vainilla y 10 cookies de chocolate. El segundo bote tiene 20 cookies de chocolate y 20 cookies de vainilla.\n",
    "\n",
    "Ahora vamos a suponer que sacamos un cookie sin ver de que bote lo sacamos. El cookie es de vainilla. ¿Cuál es la probabilidad de que el cookie venga del primer bote?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El problema de los M&Ms \n",
    "\n",
    "En 1995 M&Ms lanzó los M&M’s azules. \n",
    "\n",
    "- Antes de ese año la distibución de una bolsa era: 30% Marrones, 20% Amarillos, 20% Rojos, 10% Verdes, 10% Naranjas, 10% Marron Claros. \n",
    "- Después de 1995 la distribución en una bolsa era la siguiente: 24% Azul , 20% Verde, 16% Naranjas, 14% Amarillos, 13% Rojos, 13% Marrones\n",
    "\n",
    "Sin saber qué bolsa es cúal, sacas un M&Ms al azar de cada bolsa. Una es amarilla y otra es verde. ¿Cuál es la probabilidad de que la bolsa de la que salió el caramelo amarillo sea una bolsa de 1994?\n",
    "\n",
    "Pista: Para calcular la probabilidad a posteriori (likelihoods), tienes que multiplicar las probabilidades de sacar un amarillo de una bolsa y un verde de la otra, y viceversa.\n",
    "\n",
    "\n",
    "¿Cuál es la probabilidad de que el caramelo amarillo viniera de una bolsa de 1996?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creando un clasificador basado en el teorema de Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es un problema extraido de la página web de Chris Albon, que ha replicado un ejemplo que puedes ver en la wikipedia. Trata de reproducirlo y entenderlo.  \n",
    "\n",
    "Naive bayes is simple classifier known for doing well when only a small number of observations is available. In this tutorial we will create a gaussian naive bayes classifier from scratch and use it to predict the class of a previously unseen data point. This tutorial is based on an example on Wikipedia's [naive bayes classifier page](https://en.wikipedia.org/wiki/Naive_Bayes_classifier), I have implemented it in Python and tweaked some notation to improve explanation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data\n",
    "\n",
    "Our dataset is contains data on eight individuals. We will use the dataset to construct a classifier that takes in the height, weight, and foot size of an individual and outputs a prediction for their gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Foot_Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>6.00</td>\n",
       "      <td>180</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>5.92</td>\n",
       "      <td>190</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>5.58</td>\n",
       "      <td>170</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>5.92</td>\n",
       "      <td>165</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>5.00</td>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>female</td>\n",
       "      <td>5.50</td>\n",
       "      <td>150</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>female</td>\n",
       "      <td>5.42</td>\n",
       "      <td>130</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>female</td>\n",
       "      <td>5.75</td>\n",
       "      <td>150</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Height  Weight  Foot_Size\n",
       "0    male    6.00     180         12\n",
       "1    male    5.92     190         11\n",
       "2    male    5.58     170         12\n",
       "3    male    5.92     165         10\n",
       "4  female    5.00     100          6\n",
       "5  female    5.50     150          8\n",
       "6  female    5.42     130          7\n",
       "7  female    5.75     150          9"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty dataframe\n",
    "data = pd.DataFrame()\n",
    "\n",
    "# Create our target variable\n",
    "data['Gender'] = ['male','male','male','male','female','female','female','female']\n",
    "\n",
    "# Create our feature variables\n",
    "data['Height'] = [6,5.92,5.58,5.92,5,5.5,5.42,5.75]\n",
    "data['Weight'] = [180,190,170,165,100,150,130,150]\n",
    "data['Foot_Size'] = [12,11,12,10,6,8,7,9]\n",
    "\n",
    "# View the data\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset above is used to construct our classifier. Below we will create a new person for whom we know their feature values but not their gender. Our goal is to predict their gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Foot_Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>130</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Height  Weight  Foot_Size\n",
       "0       6     130          8"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty dataframe\n",
    "person = pd.DataFrame()\n",
    "\n",
    "# Create some feature values for this single row\n",
    "person['Height'] = [6]\n",
    "person['Weight'] = [130]\n",
    "person['Foot_Size'] = [8]\n",
    "\n",
    "# View the data \n",
    "person"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes theorem is a famous equation that allows us to make predictions based on data. Here is the classic version of the Bayes theorem:\n",
    "\n",
    "$$\\displaystyle P(A\\mid B)={\\frac {P(B\\mid A)\\,P(A)}{P(B)}}$$\n",
    "\n",
    "This might be too abstract, so let us replace some of the variables to make it more concrete. In a bayes classifier, we are interested in finding out the class (e.g. male or female, spam or ham) of an observation _given_ the data:\n",
    "\n",
    "$$p(\\text{class} \\mid \\mathbf {\\text{data}} )={\\frac {p(\\mathbf {\\text{data}} \\mid \\text{class}) * p(\\text{class})}{p(\\mathbf {\\text{data}} )}}$$\n",
    "\n",
    "where: \n",
    "\n",
    "- $\\text{class}$ is a particular class (e.g. male)\n",
    "- $\\mathbf {\\text{data}}$ is an observation's data\n",
    "- $p(\\text{class} \\mid \\mathbf {\\text{data}} )$ is called the posterior\n",
    "- $p(\\text{data|class})$ is called the likelihood\n",
    "- $p(\\text{class})$ is called the prior\n",
    "- $p(\\mathbf {\\text{data}} )$ is called the marginal probability\n",
    "\n",
    "In a bayes classifier, we calculate the posterior (technically we only calculate the numerator of the posterior, but ignore that for now) for every class for each observation. Then, classify the observation based on the class with the largest posterior value. In our example, we have one observation to predict and two possible classes (e.g. male and female), therefore we will calculate two posteriors: one for male and one for female.\n",
    "\n",
    "$$p(\\text{person is male} \\mid \\mathbf {\\text{person's data}} )={\\frac {p(\\mathbf {\\text{person's data}} \\mid \\text{person is male}) * p(\\text{person is male})}{p(\\mathbf {\\text{person's data}} )}}$$\n",
    "\n",
    "$$p(\\text{person is female} \\mid \\mathbf {\\text{person's data}} )={\\frac {p(\\mathbf {\\text{person's data}} \\mid \\text{person is female}) * p(\\text{person is female})}{p(\\mathbf {\\text{person's data}} )}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A gaussian naive bayes is probably the most popular type of bayes classifier. To explain what the name means, let us look at what the bayes equations looks like when we apply our two classes (male and female) and three feature variables (height, weight, and footsize):\n",
    "\n",
    "$${\\displaystyle {\\text{posterior (male)}}={\\frac {P({\\text{male}})\\,p({\\text{height}}\\mid{\\text{male}})\\,p({\\text{weight}}\\mid{\\text{male}})\\,p({\\text{foot size}}\\mid{\\text{male}})}{\\text{marginal probability}}}}$$\n",
    "\n",
    "$${\\displaystyle {\\text{posterior (female)}}={\\frac {P({\\text{female}})\\,p({\\text{height}}\\mid{\\text{female}})\\,p({\\text{weight}}\\mid{\\text{female}})\\,p({\\text{foot size}}\\mid{\\text{female}})}{\\text{marginal probability}}}}$$\n",
    "\n",
    "Now let us unpack the top equation a bit:\n",
    "\n",
    "- $P({\\text{male}})$ is the prior probabilities. It is, as you can see, simply the probability an observation is male. This is just the number of males in the dataset divided by the total number of people in the dataset.\n",
    "- $p({\\text{height}}\\mid{\\text{female}})\\,p({\\text{weight}}\\mid{\\text{female}})\\,p({\\text{foot size}}\\mid{\\text{female}})$ is the likelihood. Notice that we have unpacked $\\mathbf {\\text{person's data}}$ so it is now every feature in the dataset. The \"gaussian\" and \"naive\" come from two assumptions present in this likelihood:\n",
    "    1. If you look each term in the likelihood you will notice that we assume each feature is uncorrelated from each other. That is, foot size is independent of weight or height etc.. This is obviously not true, and is a \"naive\" assumption - hence the name \"naive bayes.\"\n",
    "    2. Second, we assume have that the value of the features (e.g. the height of women, the weight of women) are normally (gaussian) distributed. This means that $p(\\text{height}\\mid\\text{female})$ is calculated by inputing the required parameters into the probability density function of the normal distribution: \n",
    "\n",
    "$$ \n",
    "p(\\text{height}\\mid\\text{female})=\\frac{1}{\\sqrt{2\\pi\\text{variance of female height in the data}}}\\,e^{ -\\frac{(\\text{observation's height}-\\text{average height of females in the data})^2}{2\\text{variance of female height in the data}} }\n",
    "$$\n",
    "\n",
    "- $\\text{marginal probability}$ is probably one of the most confusing parts of bayesian approaches. In toy examples (including ours) it is completely possible to calculate the marginal probability. However, in many real-world cases, it is either extremely difficult or impossible to find the value of the marginal probability (explaining why is beyond the scope of this tutorial). This is not as much of a problem for our classifier as you might think. Why? Because we don't care what the true posterior value is, we only care which class has a the highest posterior value. And because the marginal probability is the same for all classes 1) we can ignore the denominator, 2) calculate only the posterior's numerator for each class, and 3) pick the largest numerator. That is, we can ignore the posterior's denominator and make a prediction solely on the relative values of the posterior's numerator.\n",
    "\n",
    "Okay! Theory over. Now let us start calculating all the different parts of the bayes equations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Priors can be either constants or probability distributions. In our example, this is simply the probability of being a gender. Calculating this is simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of males\n",
    "n_male = data['Gender'][data['Gender'] == 'male'].count()\n",
    "\n",
    "# Number of males\n",
    "n_female = data['Gender'][data['Gender'] == 'female'].count()\n",
    "\n",
    "# Total rows\n",
    "total_ppl = data['Gender'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of males divided by the total rows\n",
    "P_male = n_male/total_ppl\n",
    "\n",
    "# Number of females divided by the total rows\n",
    "P_female = n_female/total_ppl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that each term (e.g. $p(\\text{height}\\mid\\text{female})$) in our likelihood is assumed to be a normal pdf. For example:\n",
    "\n",
    "$$ \n",
    "p(\\text{height}\\mid\\text{female})=\\frac{1}{\\sqrt{2\\pi\\text{variance of female height in the data}}}\\,e^{ -\\frac{(\\text{observation's height}-\\text{average height of females in the data})^2}{2\\text{variance of female height in the data}} }\n",
    "$$\n",
    "\n",
    "This means that for each class (e.g. female) and feature (e.g. height) combination we need to calculate the variance and mean value from the data. Pandas makes this easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Foot_Size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>5.4175</td>\n",
       "      <td>132.50</td>\n",
       "      <td>7.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>5.8550</td>\n",
       "      <td>176.25</td>\n",
       "      <td>11.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Height  Weight  Foot_Size\n",
       "Gender                           \n",
       "female  5.4175  132.50       7.50\n",
       "male    5.8550  176.25      11.25"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group the data by gender and calculate the means of each feature\n",
    "data_means = data.groupby('Gender').mean()\n",
    "\n",
    "# View the values\n",
    "data_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Foot_Size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>0.097225</td>\n",
       "      <td>558.333333</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.035033</td>\n",
       "      <td>122.916667</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Height      Weight  Foot_Size\n",
       "Gender                                 \n",
       "female  0.097225  558.333333   1.666667\n",
       "male    0.035033  122.916667   0.916667"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group the data by gender and calculate the variance of each feature\n",
    "data_variance = data.groupby('Gender').var()\n",
    "\n",
    "# View the values\n",
    "data_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create all the variables we need. The code below might look complex but all we are doing is creating a variable out of each cell in both of the tables above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.855\n"
     ]
    }
   ],
   "source": [
    "# Means for male\n",
    "male_height_mean = data_means['Height'][data_variance.index == 'male'].values[0]\n",
    "print(male_height_mean)\n",
    "male_weight_mean = data_means['Weight'][data_variance.index == 'male'].values[0]\n",
    "male_footsize_mean = data_means['Foot_Size'][data_variance.index == 'male'].values[0]\n",
    "\n",
    "# Variance for male\n",
    "male_height_variance = data_variance['Height'][data_variance.index == 'male'].values[0]\n",
    "male_weight_variance = data_variance['Weight'][data_variance.index == 'male'].values[0]\n",
    "male_footsize_variance = data_variance['Foot_Size'][data_variance.index == 'male'].values[0]\n",
    "\n",
    "# Means for female\n",
    "female_height_mean = data_means['Height'][data_variance.index == 'female'].values[0]\n",
    "female_weight_mean = data_means['Weight'][data_variance.index == 'female'].values[0]\n",
    "female_footsize_mean = data_means['Foot_Size'][data_variance.index == 'female'].values[0]\n",
    "\n",
    "# Variance for female\n",
    "female_height_variance = data_variance['Height'][data_variance.index == 'female'].values[0]\n",
    "female_weight_variance = data_variance['Weight'][data_variance.index == 'female'].values[0]\n",
    "female_footsize_variance = data_variance['Foot_Size'][data_variance.index == 'female'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to create a function to calculate the probability density of each of the terms of the likelihood (e.g. $p(\\text{height}\\mid\\text{female})$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that calculates p(x | y):\n",
    "def p_x_given_y(x, mean_y, variance_y):\n",
    "\n",
    "    # Input the arguments into a probability density function\n",
    "    p = 1/(np.sqrt(2*np.pi*variance_y)) * np.exp((-(x-mean_y)**2)/(2*variance_y))\n",
    "    \n",
    "    # return p\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Bayes Classifier To New Data Point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright! Our bayes classifier is ready. Remember that since we can ignore the marginal probability (the demoninator), what we are actually calculating is this:\n",
    "\n",
    "$${\\displaystyle {\\text{numerator of the posterior}}={P({\\text{female}})\\,p({\\text{height}}\\mid{\\text{female}})\\,p({\\text{weight}}\\mid{\\text{female}})\\,p({\\text{foot size}}\\mid{\\text{female}})}{}}$$\n",
    "\n",
    "To do this, we just need to plug in the values of the unclassified person (height = 6), the variables of the dataset (e.g. mean of female height), and the function (`p_x_given_y`) we made above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.197071843878078e-09"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numerator of the posterior if the unclassified observation is a male\n",
    "P_male * \\\n",
    "p_x_given_y(person['Height'][0], male_height_mean, male_height_variance) * \\\n",
    "p_x_given_y(person['Weight'][0], male_weight_mean, male_weight_variance) * \\\n",
    "p_x_given_y(person['Foot_Size'][0], male_footsize_mean, male_footsize_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005377909183630018"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numerator of the posterior if the unclassified observation is a female\n",
    "P_female * \\\n",
    "p_x_given_y(person['Height'][0], female_height_mean, female_height_variance) * \\\n",
    "p_x_given_y(person['Weight'][0], female_weight_mean, female_weight_variance) * \\\n",
    "p_x_given_y(person['Foot_Size'][0], female_footsize_mean, female_footsize_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the numerator of the posterior for female is greater than male, then we predict that the person is female."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
